# Crawler
This is a small tool with simple functions and it doesn't adopt a very complicated structure. It uses a simple list to store the information crawled from web pages. The header files used are rather rudimentary. If you want to crawl some specific websites, please modify them by yourself. Since a list is used, never delete the content in the columns of the storage file at will, as this may lead to errors when reading the file. The functions of this small tool are as follows: It crawls some information from web pages and uses this information as a basis to detect whether the web pages have been updated. If you have a certain computer foundation, you can also improve it. There is still much room for improvement and quite a few shortcomings. Currently, it mainly checks for updates every half an hour. You can modify it according to your own needs. 

这是一个功能简单的小工具，并没有用很复杂的结构，是使用简单的列表来进行存储从网页爬取的信息，用的头文件很粗略，如果想要爬取一些特定的网站请自行修改，由于使用的是列表，千万不要随意删除存储文件中的列中的内容，这样可能会导致读取文件的时候出错。 这个小工具的功能如下：爬取网页的一些信息并以这些信息作为基础来检测网页是否更新，如果你有一定计算机基础也可以进行完善，它还存在很大的提升空间以及不少缺陷，目前是以每半个小时检测一次是否更新为主，你可以根据自己的需求进行修改。
